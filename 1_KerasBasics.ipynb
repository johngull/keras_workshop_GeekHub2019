{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-KerasBasics.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "DcplCHfx3Qf4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Welcome to GeekHub 2018-2019 DL workshop**\n",
        "\n",
        "First of all chech that you have runtime has GPU acceleration.\n",
        "\n",
        "We will try to play with the image classification on the toy dataset.\n",
        "\n",
        "And first we need to make some imports. You can check it now or later."
      ]
    },
    {
      "metadata": {
        "id": "2mkmVMvx42_S",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Import numpy, keras submodules and some other modules\n",
        "\n",
        "import numpy as np\n",
        "from keras import layers, initializers, optimizers, regularizers\n",
        "from keras import datasets, models, callbacks, applications\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Q3z3v6p4ib8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And because of \"International Women's Day\" we will take \"Fashion MNIST\""
      ]
    },
    {
      "metadata": {
        "id": "chQ9L7Ap6a5N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fashion_mnist = datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWG8gNQ75LaF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets check whats inside"
      ]
    },
    {
      "metadata": {
        "id": "FljoIgOS4c-5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Train shape:\", train_images.shape)\n",
        "print(\"Unique values in labels:\", np.unique(train_labels))\n",
        "print(\"Test shape:\", test_images.shape)\n",
        "print(\"Train images min:\", np.min(train_images), \"max:\", np.max(train_images))\n",
        "\n",
        "print(\"First image:\")\n",
        "plt.figure()\n",
        "plt.imshow(train_images[0], cmap=plt.cm.binary)\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "print(\"Class for this image:\", class_names[train_labels[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AokVJcOc8spM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And lets see more examples"
      ]
    },
    {
      "metadata": {
        "id": "iyhTyyar8vSg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jA05Wh1s9M00",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Deep Learning models like normalized values, so lets normalize images.\n",
        "\n",
        "For simplicity we can divide on 255.\n",
        "But you can use StandardScaler also. Be careful with the shapes in such case.\n",
        "\n",
        "Also be carefull with the types: `train_images` and `test_images` are uint8.\n",
        "\n",
        "Please try to make it by yourself before looking on solution\n"
      ]
    },
    {
      "metadata": {
        "id": "kGbPVAvW-29v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train_images_scaled = \n",
        "#test_images_scaled = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mPcH6Wer9MYz",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "\n",
        "#solution #1\n",
        "# train_images_scaled = train_images.astype(np.float32)/255.0\n",
        "# test_images_scaled = test_images.astype(np.float32)/255.0\n",
        "\n",
        "#solution #2\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "# train_images_scaled = scaler.fit_transform(train_images.astype(np.float32).reshape(-1, 28*28)).reshape(-1, 28, 28)\n",
        "# test_images_scaled = scaler.transform(test_images.astype(np.float32).reshape(-1, 28*28)).reshape(-1, 28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fm0KergTACHj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you plan to use classic `categorical_crossentropy` you should also do one-hot encoding for labels to calculate loss.\n",
        "But now in keras there is special loss to use raw labels. And this is the way for PyTorch also.\n",
        "So, lets keep labels as it is."
      ]
    },
    {
      "metadata": {
        "id": "48mbIE5SAoka",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Finaly** we can do deep learning :)\n",
        "Lets try something super simple and create \"retro\" model - multilayer perceptron. And try to use it for our task.\n",
        "\n",
        "We will start right from the functional API of Keras. Sequential is ok for such simple examples, but functional API is much better with complex models.\n",
        "\n",
        "First of all lets discuss how models and layers created and build our first model.\n",
        "\n",
        "Can you make it deeper?"
      ]
    },
    {
      "metadata": {
        "id": "JiPgYEBYBXEO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getModel(input_shape):\n",
        "  inp = layers.Input(input_shape)\n",
        "  flatten = layers.Flatten()(inp) # (batch, width, height) -> (batch, length)\n",
        "  fc = layers.Dense(100, activation='relu')(flatten)\n",
        "  # fc = ?\n",
        "  out = layers.Dense(10, activation='softmax')(fc)\n",
        "  \n",
        "  return models.Model(inp, out)\n",
        "  \n",
        "model = getModel((28, 28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F40krjDCCyI_",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Possible solution\n",
        "# def getModel(input_shape):\n",
        "#   inp = layers.Input(input_shape)\n",
        "#   flatten = layers.Flatten()(inp) # (batch, width, height) -> (batch, length)\n",
        "#   fc = layers.Dense(100, activation='relu')(flatten)\n",
        "#   fc = layers.Dense(40, activation='relu')(fc)\n",
        "#   out = layers.Dense(10, activation='softmax')(fc)\n",
        "  \n",
        "#   return models.Model(inp, out)\n",
        "  \n",
        "# model = getModel((28, 28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gBYsY-4rDFuu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To start training we need `compile` model - ask keras to prepare graph, losses, metrics and optimizer.\n",
        "\n",
        "Pay attention that we used 'sparse_categorical_crossentropy' as we use raw labels.\n",
        "\n",
        "For first time we will pass strings with the names to let keras use everything with the default parameters.\n",
        "But you can use your functions for loss and metrics and optimizer class as optimizer."
      ]
    },
    {
      "metadata": {
        "id": "-ur4Uph-DAC1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sW6A0lpgEON-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we are ready for the fit-predict :)\n",
        "\n",
        "But wait, you are not the first day in data science. Lets divide train on train and validation first."
      ]
    },
    {
      "metadata": {
        "id": "eUD5WeYHEadr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_X, val_X, train_Y, val_Y = train_test_split(train_images_scaled, train_labels, test_size=0.2, random_state=42, stratify=train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qUZ31gntFIbZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ok, now we can make fit.\n",
        "Interface very close to sklearn with some modifications.\n",
        "\n",
        "Here default mode is verbose as usually train may last long."
      ]
    },
    {
      "metadata": {
        "id": "I7rRo5F6E_-p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(train_X, train_Y,\n",
        "          validation_data=(val_X, val_Y),\n",
        "          batch_size=64,\n",
        "          epochs=10\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVSNbdvmHTHn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "88% accuracy - not so bad. Maybe you already have more? :)\n",
        "\n",
        "Remember that we have test set also. Lets check values on it."
      ]
    },
    {
      "metadata": {
        "id": "QCqxE9HTHfl4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images_scaled, test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fjY7SmG-Hohg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I got 87%. Nice.\n",
        "\n",
        "But can we do better?\n",
        "I hope your answer is \"Sure!\""
      ]
    },
    {
      "metadata": {
        "id": "nRtlclGEH6vq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You should already know that for images better to use **convolution networks**.\n",
        "Lets start with the classic architectures and make something VGG16-like.\n",
        "\n",
        "It should be easy for you to fill the gap.\n",
        "\n",
        "You can also play with filters count or kernel_size.\n",
        "\n",
        "Please note that activation can be used as separate layer. It is same as use it inside `Conv2D` layer, but leave you a place for normalization layers."
      ]
    },
    {
      "metadata": {
        "id": "3hQQOTIqImTl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getModel(input_shape):\n",
        "  inp = layers.Input(input_shape)\n",
        "  \n",
        "  conv = layers.Conv2D(32, 3, padding='same')(inp) #filters=32, kernel size=3\n",
        "  conv = layers.Activation('relu')(conv)\n",
        "  conv = layers.Conv2D(32, 3, padding='same')(conv)\n",
        "  conv = layers.Activation('relu')(conv)\n",
        "  pool = layers.MaxPool2D()(conv) #default pool_size=2\n",
        "  \n",
        "  #?\n",
        "  \n",
        "  pool = layers.GlobalMaxPool2D()(conv)  \n",
        "  # ?\n",
        "  out = layers.Activation('softmax')(fc)    \n",
        "  return models.Model(inp, out)\n",
        "  \n",
        "model = getModel((28, 28, 1))\n",
        "\n",
        "model.compile(\n",
        "    #?\n",
        "              )\n",
        "\n",
        "model.fit(train_X.reshape(-1, 28, 28, 1), train_Y,\n",
        "          validation_data=(val_X.reshape(-1, 28, 28, 1), val_Y),\n",
        "          batch_size=64,\n",
        "          epochs=15\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lLAOjwTf_8-s",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Possible solution\n",
        "\n",
        "# def getModel(input_shape):\n",
        "#   inp = layers.Input(input_shape)\n",
        "  \n",
        "#   conv = layers.Conv2D(32, 3, padding='same')(inp) #filters=32, kernel size=3\n",
        "#   conv = layers.Activation('relu')(conv)\n",
        "#   conv = layers.Conv2D(32, 3, padding='same')(conv)\n",
        "#   conv = layers.Activation('relu')(conv)\n",
        "#   pool = layers.MaxPool2D()(conv) #default pool_size=2\n",
        "  \n",
        "#   conv = layers.Conv2D(64, 3, padding='same')(pool)\n",
        "#   conv = layers.Activation('relu')(conv)\n",
        "#   conv = layers.Conv2D(64, 3, padding='same')(conv)\n",
        "#   conv = layers.Activation('relu')(conv)\n",
        "#   pool = layers.MaxPool2D()(conv) \n",
        "  \n",
        "#   conv = layers.Conv2D(128, 3, padding='same')(pool) \n",
        "#   conv = layers.Activation('relu')(conv)\n",
        "#   conv = layers.Conv2D(128, 3, padding='same')(conv)\n",
        "#   conv = layers.Activation('relu')(conv)\n",
        "  \n",
        "#   pool = layers.GlobalMaxPool2D()(conv)  \n",
        "#   fc = layers.Dense(40)(pool)\n",
        "#   fc = layers.Activation('relu')(fc)\n",
        "#   fc = layers.Dense(10)(fc)\n",
        "#   out = layers.Activation('softmax')(fc)\n",
        "  \n",
        "  \n",
        "#   return models.Model(inp, out)\n",
        "  \n",
        "# model = getModel((28, 28, 1))\n",
        "\n",
        "# model.compile(optimizer='adam', \n",
        "#               loss='sparse_categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.fit(train_X.reshape(-1, 28, 28, 1), train_Y,\n",
        "#           validation_data=(val_X.reshape(-1, 28, 28, 1), val_Y),\n",
        "#           batch_size=64,\n",
        "#           epochs=13\n",
        "#          )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0T57LfzafHsv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hm... looks like overfit.\n",
        "Hope you got it also. If not, go back and do it :)\n",
        "\n",
        "What we can do with this:\n",
        "- reduce model size\n",
        "- regularization\n",
        "- dropout as regularization\n",
        "- early stopping\n",
        "- other models\n",
        "- learning rate chnages\n",
        "- ...\n",
        "\n",
        "Lets do easiest points: dropout and early stopping+reduce learning rate on plateau."
      ]
    },
    {
      "metadata": {
        "id": "z4OpwpX2g5A5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getModel(input_shape):\n",
        "  inp = layers.Input(input_shape)\n",
        "  \n",
        "  conv = layers.Conv2D(32, 3, padding='same')(inp) #filters=32, kernel size=3\n",
        "  conv = layers.Activation('relu')(conv)\n",
        "  conv = layers.Conv2D(32, 3, padding='same')(conv)\n",
        "  conv = layers.Activation('relu')(conv)\n",
        "  pool = layers.MaxPool2D()(conv) #default pool_size=2\n",
        "  \n",
        "  conv = layers.Conv2D(64, 3, padding='same')(pool)\n",
        "  conv = layers.Activation('relu')(conv)\n",
        "  conv = layers.Conv2D(64, 3, padding='same')(conv)\n",
        "  conv = layers.Activation('relu')(conv)\n",
        "  pool = layers.MaxPool2D()(conv) \n",
        "  \n",
        "  conv = layers.Conv2D(128, 3, padding='same')(pool) \n",
        "  conv = layers.Activation('relu')(conv)\n",
        "  conv = layers.Conv2D(128, 3, padding='same')(conv)\n",
        "  conv = layers.Activation('relu')(conv)\n",
        "  \n",
        "  pool = layers.GlobalMaxPool2D()(conv)\n",
        "  # dropout\n",
        "  fc = layers.Dense(40)(pool)\n",
        "  fc = layers.Activation('relu')(fc)\n",
        "  # dropout\n",
        "  fc = layers.Dense(10)(fc)\n",
        "  out = layers.Activation('softmax')(fc)   \n",
        "  return models.Model(inp, out)\n",
        "  \n",
        "model = getModel((28, 28, 1))\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_X.reshape(-1, 28, 28, 1), train_Y,\n",
        "          validation_data=(val_X.reshape(-1, 28, 28, 1), val_Y),\n",
        "          batch_size=64,\n",
        "          epochs=15,\n",
        "          callbacks=[\n",
        "              callbacks.ModelCheckpoint('weights.h5', verbose=1, save_best_only=True, save_weights_only=True),\n",
        "              callbacks.ReduceLROnPlateau(patience=2, verbose=1),\n",
        "              callbacks.EarlyStopping(patience=4, verbose=1)\n",
        "          ]\n",
        "         )\n",
        "\n",
        "model.load_weights('weights.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZT4lckXKAx2M",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Possible solution\n",
        "\n",
        "# def getModel(input_shape):\n",
        "#   inp = layers.Input(input_shape)\n",
        "  \n",
        "#   conv = layers.Conv2D(32, 3, padding='same')(inp) #filters=64, kernel size=3\n",
        "#   conv = layers.Activation('relu')(conv)\n",
        "#   conv = layers.Conv2D(32, 3, padding='same')(conv)\n",
        "#   conv = layers.Activation('relu')(conv)\n",
        "#   pool = layers.MaxPool2D()(conv) #default pool_size=2\n",
        "  \n",
        "#   conv = layers.Conv2D(64, 3, padding='same')(pool)\n",
        "#   conv = layers.Activation('relu')(conv)\n",
        "#   conv = layers.Conv2D(64, 3, padding='same')(conv)\n",
        "#   conv = layers.Activation('relu')(conv)\n",
        "#   pool = layers.MaxPool2D()(conv) \n",
        "  \n",
        "#   conv = layers.Conv2D(128, 3, padding='same')(pool) \n",
        "#   conv = layers.Activation('relu')(conv)\n",
        "#   conv = layers.Conv2D(128, 3, padding='same')(conv)\n",
        "#   conv = layers.Activation('relu')(conv)\n",
        "  \n",
        "#   pool = layers.GlobalMaxPool2D()(conv)\n",
        "#   pool = layers.Dropout(0.2)(pool)\n",
        "#   fc = layers.Dense(40)(pool)\n",
        "#   fc = layers.Activation('relu')(fc)\n",
        "#   fc = layers.Dropout(0.1)(fc)\n",
        "#   fc = layers.Dense(10)(fc)\n",
        "#   out = layers.Activation('softmax')(fc)\n",
        "  \n",
        "  \n",
        "#   return models.Model(inp, out)\n",
        "  \n",
        "# model = getModel((28, 28, 1))\n",
        "\n",
        "# model.compile(optimizer='adam', \n",
        "#               loss='sparse_categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.fit(train_X.reshape(-1, 28, 28, 1), train_Y,\n",
        "#           validation_data=(val_X.reshape(-1, 28, 28, 1), val_Y),\n",
        "#           batch_size=64,\n",
        "#           epochs=15,\n",
        "#           callbacks=[\n",
        "#               callbacks.ModelCheckpoint('weights.h5', verbose=1, save_best_only=True, save_weights_only=True),\n",
        "#               callbacks.ReduceLROnPlateau(patience=2, verbose=1),\n",
        "#               callbacks.EarlyStopping(patience=4, verbose=1)\n",
        "#           ]\n",
        "#          )\n",
        "\n",
        "# model.load_weights('weights.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oPy5l_xykGPA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ok. Overfit happened, but we took correct point. And it looks best from what we saw.\n",
        "Lets verify with the test set."
      ]
    },
    {
      "metadata": {
        "id": "A_kXXJoxkVFr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images_scaled.reshape(-1, 28, 28, 1), test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CPSTyqHckfe2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Almost 93% accuracy. Good improvement from 87% with the multilayered perceptron."
      ]
    },
    {
      "metadata": {
        "id": "9q6WUJzVE1te",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets try another model structure and look on several additional possibilities.\n",
        "\n",
        "1. Code for generating model graph is just a code, so you can organize it in loops, generators, functions, classes... Whatever you want\n",
        "2. Pay attention how easily we added batch normalization\n",
        "3. Keras support multiple inputs and outputs. While it is not needed here, I added 2 outputs for the next model. Please check how it is used in `Model`, `compile` and `fit`"
      ]
    },
    {
      "metadata": {
        "id": "nZqLloNrmzpL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "regularization = regularizers.L1L2(0, 1e-4)\n",
        "\n",
        "def res_block(x):\n",
        "  count = int(x.shape[-1])\n",
        "  \n",
        "  conv = layers.Conv2D(count, 3, padding='same', kernel_regularizer=regularization)(x)\n",
        "  conv = layers.BatchNormalization()(conv)\n",
        "  conv = layers.Activation('relu')(conv)\n",
        "  conv = layers.Conv2D(count, 3, padding='same', kernel_regularizer=regularization)(conv)\n",
        "  conv = layers.BatchNormalization()(conv)\n",
        "  conv = layers.Activation('relu')(conv)\n",
        "  \n",
        "  return layers.add([conv, x])\n",
        "\n",
        "\n",
        "def strided_res_block(x, filters):\n",
        "  conv = layers.Conv2D(filters, 3, padding='same', strides=(2,2), kernel_regularizer=regularization)(x)\n",
        "  conv = layers.BatchNormalization()(conv)\n",
        "  conv = layers.Activation('relu')(conv)\n",
        "  conv = layers.Conv2D(filters, 3, padding='same', kernel_regularizer=regularization)(conv)\n",
        "  conv = layers.BatchNormalization()(conv)\n",
        "  \n",
        "  shortcut = layers.Conv2D(filters, 1, padding='same', strides=(2,2), kernel_regularizer=regularization)(x)\n",
        "  shortcut = layers.BatchNormalization()(shortcut)\n",
        "  \n",
        "  s = layers.add([conv, shortcut])\n",
        "  s = layers.Activation('relu')(s)\n",
        "  \n",
        "  return s\n",
        "\n",
        "\n",
        "def getModel(input_shape):\n",
        "  inp = layers.Input(input_shape)\n",
        "  \n",
        "  conv = layers.Conv2D(64, 3, padding='same', strides=(2,2), kernel_regularizer=regularization)(inp)\n",
        "  conv = layers.BatchNormalization()(conv)\n",
        "  conv = layers.Activation('relu')(conv)\n",
        "    \n",
        "  conv = res_block(conv)\n",
        "  conv = res_block(conv)\n",
        "  \n",
        "  conv = strided_res_block(conv, 128)\n",
        "  conv = res_block(conv)\n",
        "  \n",
        "  out2 = layers.GlobalAveragePooling2D()(conv)\n",
        "  out2 = layers.Dropout(0.2)(out2)\n",
        "  out2 = layers.Dense(10, activation='softmax', name='aux_out')(out2)\n",
        "  \n",
        "  conv = strided_res_block(conv, 256)\n",
        "  conv = res_block(conv)\n",
        "  \n",
        "  conv = strided_res_block(conv, 512)\n",
        "  conv = res_block(conv)   \n",
        "  \n",
        "  pool = layers.GlobalAveragePooling2D()(conv)\n",
        "  pool = layers.Dropout(0.2)(pool)\n",
        "  fc = layers.Dense(50)(pool)\n",
        "  fc = layers.Activation('relu')(fc)\n",
        "  fc = layers.Dense(10)(fc)\n",
        "  out = layers.Activation('softmax', name='out')(fc)\n",
        "   \n",
        "  return models.Model(inputs=inp, outputs=[out, out2])\n",
        "  \n",
        "  \n",
        "model = getModel((28, 28, 1))\n",
        "\n",
        "model.compile(optimizer=optimizers.Adam(1e-3), \n",
        "              loss=['sparse_categorical_crossentropy', 'sparse_categorical_crossentropy'],\n",
        "              loss_weights=[1, 0.5],\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_X.reshape(-1, 28, 28, 1), [train_Y, train_Y],\n",
        "          validation_data=(val_X.reshape(-1, 28, 28, 1), [val_Y, val_Y]),\n",
        "          batch_size=256,\n",
        "          epochs=25,\n",
        "          callbacks=[\n",
        "              callbacks.ModelCheckpoint('weights.h5', verbose=1, \n",
        "                                        save_best_only=True, save_weights_only=True,\n",
        "                                        monitor='val_out_loss'),\n",
        "              callbacks.ReduceLROnPlateau(patience=2, verbose=1, monitor='val_out_loss'),\n",
        "              callbacks.EarlyStopping(patience=5, verbose=1, monitor='val_out_loss')\n",
        "          ]\n",
        "         )\n",
        "\n",
        "model.load_weights('weights.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dHqj-YXsFijH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "With the 2 outputs `predict` also return 2 numpy arrays. We are interested only in first one."
      ]
    },
    {
      "metadata": {
        "id": "rFC1iiDoiRFG",
        "colab_type": "code",
        "outputId": "62c6b8c8-b46e-4ca9-efd2-e66cb550a7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "predict = model.predict(test_images_scaled.reshape(-1, 28, 28, 1))[0]\n",
        "labels_predict = np.argmax(predict, axis=-1)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels_predict, test_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qshCV6HgFqcT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Accuracy not improved.\n",
        "So our resnet-like structure not helped.\n",
        "Thats may have lot of explanations: from wrong hyperparameters to any new structure ould not help much.\n",
        "\n",
        "You can play with the different structures, by your own.\n",
        "But, now lets try some other tricks with another dataset. \n",
        "Check 2nd colab notebook."
      ]
    }
  ]
}